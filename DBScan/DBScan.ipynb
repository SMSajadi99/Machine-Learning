{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h1 align=\"center\">Machine Learning in Python</h1>\n",
    "    <h3 align=\"center\">DBScan</h3>\n",
    "    <h4 align=\"center\"><a href=\"https://www.linkedin.com/public-profile/settings?trk=d_flagship3_profile_self_view_public_profile&lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_self_edit_top_card%3BhFw1W2M%2FTMCAYZp6pzKt1Q%3D%3D\">Seyed Mohammad Sajadi</a></h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topics:\n",
    "\n",
    "- [ ] What is DBScan\n",
    "- [ ] DBScan step by step\n",
    "- [ ] DBScan vs K-means\n",
    "- [ ] DBScan in Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is DBScan?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBSCAN (Density-Based Spatial Clustering of Applications with Noise) \n",
    "Finds core samples of high density and expands clusters from them. ... This is not a maximum bound on the distances of points within a cluster. This is the most important DBSCAN parameter to choose appropriately for your data set and distance function.\n",
    "\n",
    "Density-Based Clustering refers to unsupervised learning methods that identify distinctive groups/clusters in the data, based on the idea that a cluster in data space is a contiguous region of high point density, separated from other such clusters by contiguous regions of low point density.\n",
    "\n",
    "Density-Based Spatial Clustering of Applications with Noise (DBSCAN) is a base algorithm for density-based clustering. It can discover clusters of different shapes and sizes from a large amount of data, which is containing noise and outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBScan (Step by Step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"1.JPG\" width=75%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"2.JPG\" width=75%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually 2 parameters for DBSCAN to Optimize \n",
    "* <font color='red'>Epsilon</font> \n",
    "* <font color='red'>Minimum Points</font>\n",
    "\n",
    "<font color='red'>Epsilon $(\\epsilon)$ </font> determines how much close the points should be to be considered a part of a cluster and <font color='red'>Minimum Points _(MinPts)_ </font> determines how many number of samples (points) need to be considered around a point within the radius $\\epsilon$ to be considered as a _Core Point_. _MinPts_ include the point in consideration itself.   \n",
    "\n",
    "\n",
    "We start with loading the Canada Weather Data-Set. We will __cluster weather stations that show similar weather conditions__. Selection of features and applications on clustering will be shown. Since the data domain is not so well understood, it is always best to play around with $\\epsilon$ and _MinPts_ parameter in Scikit learn.  \n",
    "\n",
    "* Core — This is a point that has at least m points within distance n from itself.\n",
    "* Border — This is a point that has at least one Core point at a distance n.\n",
    "* Noise — This is a point that is neither a Core nor a Border. And it has less than m points within distance n from itself. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://miro.medium.com/max/627/1*yT96veo7Zb5QeswV7Vr7YQ.png\" width=45%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"3.JPG\" width=75%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"4.JPG\" width=75%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"5.JPG\" width=75%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"6.JPG\" width=75%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"7.JPG\" width=75%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"8.JPG\" width=75%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBScan vs K-means?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://miro.medium.com/max/1339/0*xu3GYMsWu9QiKNOo.png\" width=75%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBScan Animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://miro.medium.com/proxy/1*tc8UF-h0nQqUfLC8-0uInQ.gif\" width=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the DataFrame:  (1341, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stn_Name</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Prov</th>\n",
       "      <th>Tm</th>\n",
       "      <th>DwTm</th>\n",
       "      <th>D</th>\n",
       "      <th>Tx</th>\n",
       "      <th>DwTx</th>\n",
       "      <th>Tn</th>\n",
       "      <th>...</th>\n",
       "      <th>DwP</th>\n",
       "      <th>P%N</th>\n",
       "      <th>S_G</th>\n",
       "      <th>Pd</th>\n",
       "      <th>BS</th>\n",
       "      <th>DwBS</th>\n",
       "      <th>BS%</th>\n",
       "      <th>HDD</th>\n",
       "      <th>CDD</th>\n",
       "      <th>Stn_No</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHEMAINUS</td>\n",
       "      <td>48.935</td>\n",
       "      <td>-123.742</td>\n",
       "      <td>BC</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>273.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1011500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COWICHAN LAKE FORESTRY</td>\n",
       "      <td>48.824</td>\n",
       "      <td>-124.133</td>\n",
       "      <td>BC</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1012040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LAKE COWICHAN</td>\n",
       "      <td>48.829</td>\n",
       "      <td>-124.052</td>\n",
       "      <td>BC</td>\n",
       "      <td>6.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>168.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1012055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Stn_Name     Lat     Long Prov   Tm  DwTm    D    Tx  DwTx  \\\n",
       "0               CHEMAINUS  48.935 -123.742   BC  8.2   0.0  NaN  13.5   0.0   \n",
       "1  COWICHAN LAKE FORESTRY  48.824 -124.133   BC  7.0   0.0  3.0  15.0   0.0   \n",
       "2           LAKE COWICHAN  48.829 -124.052   BC  6.8  13.0  2.8  16.0   9.0   \n",
       "\n",
       "    Tn  ...  DwP    P%N  S_G    Pd  BS  DwBS  BS%    HDD  CDD   Stn_No  \n",
       "0  1.0  ...  0.0    NaN  0.0  12.0 NaN   NaN  NaN  273.3  0.0  1011500  \n",
       "1 -3.0  ...  0.0  104.0  0.0  12.0 NaN   NaN  NaN  307.0  0.0  1012040  \n",
       "2 -2.5  ...  9.0    NaN  NaN  11.0 NaN   NaN  NaN  168.1  0.0  1012055  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df = pd.read_csv('weather-stations.csv')\n",
    "print (\"Shape of the DataFrame: \", weather_df.shape)\n",
    "weather_df.head(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1341 entries, 0 to 1340\n",
      "Data columns (total 25 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Stn_Name  1341 non-null   object \n",
      " 1   Lat       1341 non-null   float64\n",
      " 2   Long      1341 non-null   float64\n",
      " 3   Prov      1341 non-null   object \n",
      " 4   Tm        1256 non-null   float64\n",
      " 5   DwTm      1256 non-null   float64\n",
      " 6   D         357 non-null    float64\n",
      " 7   Tx        1260 non-null   float64\n",
      " 8   DwTx      1260 non-null   float64\n",
      " 9   Tn        1260 non-null   float64\n",
      " 10  DwTn      1260 non-null   float64\n",
      " 11  S         586 non-null    float64\n",
      " 12  DwS       586 non-null    float64\n",
      " 13  S%N       198 non-null    float64\n",
      " 14  P         1227 non-null   float64\n",
      " 15  DwP       1227 non-null   float64\n",
      " 16  P%N       209 non-null    float64\n",
      " 17  S_G       798 non-null    float64\n",
      " 18  Pd        1227 non-null   float64\n",
      " 19  BS        0 non-null      float64\n",
      " 20  DwBS      0 non-null      float64\n",
      " 21  BS%       0 non-null      float64\n",
      " 22  HDD       1256 non-null   float64\n",
      " 23  CDD       1256 non-null   float64\n",
      " 24  Stn_No    1341 non-null   object \n",
      "dtypes: float64(22), object(3)\n",
      "memory usage: 262.0+ KB\n"
     ]
    }
   ],
   "source": [
    "weather_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are 25 columns and now we need to learn more about the Columns, The names that are difficult to guess \n",
    "* Stn_Name === Station Name\n",
    "* Prov     === Province\n",
    "* Tm       === Mean Temperature (°C)\n",
    "* Tn       === Lowest Monthly Minimum Temperature \n",
    "* Tx       === Highest Monthly Maximum Temperature \n",
    "* DwTm     === Days Without Valid Mean Temperature\n",
    "* DwTx     === Days Without Valid Maximum Temperature\n",
    "* DwTn     === Days Without Valid Minimum Temperature\n",
    "* D        === Mean Temperature Difference from Normal\n",
    "* S        === Snowfall (cm)\n",
    "* DwS      === Days Without Snowfall\n",
    "* S%N      === Percent of Normal Snowfall\n",
    "* P        === Total Precipitation (mm)\n",
    "* DwP      === Days Without Valid Precipitation\n",
    "* P%N      === Percent of Normal Precipitation\n",
    "* Pd       === No. of days with precipitation 1mm or More \n",
    "* BS       === Bright Sunshine days\n",
    "* DwBS     === Days Without valid Bright Sunshine\n",
    "* BS%      === Percent of Normal Bright Sunshine\n",
    "* HDD      === Degree Days Below $18^{\\circ}$C \n",
    "* CDD      === Degree Days Above $18^{\\circ}$C\n",
    "* Stn_No   === Station Number; Climate Station Identifier (1st 3 Digits==Indicate drainage basin, Last 4 Digits Sorting Alphabetically)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stn_Name       0\n",
       "Lat            0\n",
       "Long           0\n",
       "Prov           0\n",
       "Tm            85\n",
       "DwTm          85\n",
       "D            984\n",
       "Tx            81\n",
       "DwTx          81\n",
       "Tn            81\n",
       "DwTn          81\n",
       "S            755\n",
       "DwS          755\n",
       "S%N         1143\n",
       "P            114\n",
       "DwP          114\n",
       "P%N         1132\n",
       "S_G          543\n",
       "Pd           114\n",
       "BS          1341\n",
       "DwBS        1341\n",
       "BS%         1341\n",
       "HDD           85\n",
       "CDD           85\n",
       "Stn_No         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the nan values in the dataframe \n",
    "weather_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Dropping Rows that contains NaN on Mean, Max, Min Temperature Column:  (1255, 25)\n"
     ]
    }
   ],
   "source": [
    "weather_df.dropna(subset=['Tm', 'Tx', 'Tn'], inplace=True)\n",
    "print (\"After Dropping Rows that contains NaN on Mean, Max, Min Temperature Column: \", weather_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More on Google Colab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
